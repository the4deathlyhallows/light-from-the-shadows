Skip to content
Chat history

You said:
what is the tstats command for
ChatGPT said:
In Splunk, the tstats command is a high-performance statistical command used to query indexed fields (especially in accelerated data models or summary indexes) much faster than a regular stats search.
Letâ€™s break it down clearly ğŸ‘‡

ğŸ§  What tstats Does
tstats = â€œtransformed statsâ€
It lets you:
Run statistical aggregations (count, sum, avg, etc.)
On indexed fields (like index, sourcetype, host, and accelerated CIM fields)
Without fully loading raw events, making it much faster than stats or search.
âš™ï¸ Basic Syntax
| tstats <stats-functions> FROM <datasets> [WHERE <criteria>] [BY <fields>]
ğŸ’¡ Examples
1. Count events by index
| tstats count WHERE index=* BY index
â†’ Shows total event count per index.
2. Count events by sourcetype
| tstats count WHERE index=security BY sourcetype
â†’ Counts security index events per sourcetype.
3. Summarize data model fields
If you have a CIM data model accelerated (like Endpoint or Network_Traffic):
| tstats count FROM datamodel=Endpoint.Processes BY "Processes.user", "Processes.process_name"
â†’ Pulls from the accelerated data model instead of raw logs. This is extremely fast.
4. Filtered example
| tstats count FROM datamodel=Authentication WHERE "Authentication.action"="failure" BY "Authentication.user"
â†’ Counts failed logins per user using the Authentication data model.
ğŸš€ Why Use tstats Instead of stats
Feature	tstats	stats
Speed	Very fast (metadata-level, no event expansion)	Slower (loads raw events)
Data Source	Indexed fields / accelerated data models	Any field (even unindexed)
Best for	Summarized reports, CIM acceleration, dashboards	Ad-hoc searches, event-level analysis
âš ï¸ Limitations
Can only use indexed fields or accelerated data model fields.
Cannot extract fields at search time.
You canâ€™t use it directly with fields that donâ€™t exist in the index time metadata.
âœ… Quick Summary
tstats is best used when:
You want fast metrics (counts, averages, sums, etc.).
Youâ€™re working with large datasets.
Youâ€™re using data model acceleration (CIM).
Youâ€™re building dashboards or detections that require quick rollups.
Would you like me to show how tstats is typically used in detection engineering (like counting failed logins, process creation anomalies, or network traffic spikes)?
You said:
what about tstats summariesonly=true
ChatGPT said:
Excellent question â€” this is one that really separates power users and detection engineers from casual Splunk users ğŸ‘
Letâ€™s unpack what summariesonly=true in tstats really means.

ğŸ§© summariesonly=true â€” What It Does
The summariesonly=true argument in a tstats search tells Splunk to only search data model acceleration summaries, and skip raw indexed data completely.
In short:

ğŸ’¡ It forces Splunk to use summary (accelerated) data only â€” not the original event data.
ğŸ” Why This Matters
When you accelerate a data model, Splunk builds summary files (optimized pre-aggregated data stored in summary directories).
tstats summariesonly=true tells Splunk:
â€œUse those summaries, donâ€™t touch the raw index.â€
This can make a search 10â€“100x faster, especially on large datasets.
âš™ï¸ Syntax
| tstats summariesonly=true count FROM datamodel=Authentication BY "Authentication.user"
This:
Pulls only accelerated summary data from the Authentication data model.
Does not look at index= or sourcetype= raw events.
âš¡ Example Comparisons
ğŸ”¸ Without summariesonly (default)
| tstats count FROM datamodel=Authentication WHERE "Authentication.action"="failure"
âœ… Uses summaries if they exist,
âŒ but may also fall back to raw data if summaries arenâ€™t up-to-date.
ğŸ”¸ With summariesonly=true
| tstats summariesonly=true count FROM datamodel=Authentication WHERE "Authentication.action"="failure"
âœ… Uses only existing accelerated summaries
âŒ Ignores any events not yet summarized (e.g., recent events not yet accelerated)
ğŸ§  When to Use It
Use Case	Should You Use summariesonly=true?	Why
Fast dashboards / reports	âœ… Yes	Keeps searches lightweight
CIM-based detections using accelerated data models	âœ… Yes	Ensures consistent performance
Real-time searches / hunting	âš ï¸ Maybe	You might miss the most recent events
Investigations (need full fidelity)	âŒ No	You want raw logs too
ğŸš¨ Pro Tip for Detection Engineers
When youâ€™re writing detections based on CIM models, itâ€™s common to use:
| tstats summariesonly=true count FROM datamodel=Endpoint.Processes BY Processes.user, Processes.process_name
âœ… Super fast for dashboards or trend jobs
âš ï¸ But if youâ€™re testing a new correlation or alert, drop the flag until you verify full event coverage:
| tstats count FROM datamodel=Endpoint.Processes BY Processes.user, Processes.process_name
ğŸ§¾ Summary Table
Option	Behavior
summariesonly=false	Uses both summaries and raw data (default)
summariesonly=true	Uses only accelerated summaries
(no flag specified)	Defaults to false â€” Splunk can fall back to raw data
âœ… Bottom Line
Use summariesonly=true when:
Youâ€™re running scheduled reports, dashboards, or detections on accelerated data models
You prioritize speed and consistency
Avoid it when:
You need real-time or complete coverage (may miss fresh, unaccelerated events)
Would you like me to show an example of how tstats summariesonly=true fits into a real detection search (e.g., process spawning from unusual parent or failed logons across hosts)?
You said:
what about the values command
ChatGPT said:
Excellent â€” youâ€™re getting into the core of Splunk stats functions, which are the backbone of detection engineering and data summarization.
Letâ€™s go deep but cleanly:

ğŸ§© values() â€” What It Does
The values() function in Splunk is used with commands like stats, eventstats, or tstats to:
Return all unique values of a field as a multivalue list.
So instead of giving you a count, sum, or average, it gives you a set of distinct values seen in that group.
âš™ï¸ Basic Syntax
| stats values(<field>) BY <grouping-field>
ğŸ’¡ Example 1 â€” Unique Users per Host
index=security sourcetype=authentication
| stats values(user) AS users BY host
ğŸ§  Meaning:
For each host, list all unique users that logged in.
âœ… Output might look like:
host	users
win10-lab	admin, robert, svc_account
srv-prod01	svc_account, domain_admin
ğŸ’¡ Example 2 â€” Unique Processes per User
| tstats values(Processes.process_name) AS process_list FROM datamodel=Endpoint.Processes BY Processes.user
â†’ Lists all unique process names per user â€” very common in detection engineering.
ğŸ’¡ Example 3 â€” Combine with count for more insight
index=windows EventCode=4688
| stats count values(New_Process_Name) AS unique_processes BY user
âœ… Shows how many processes a user ran, plus a list of which ones.
ğŸ§  How It Differs from Other Functions
Function	Purpose	Example Output
values(field)	All unique values	chrome.exe, powershell.exe, cmd.exe
list(field)	All values (including duplicates)	chrome.exe, chrome.exe, cmd.exe
dc(field)	Distinct count	3
count(field)	Count of events with that field	10
âš¡ Using values() in tstats
You can absolutely use it inside tstats, like so:
| tstats values(Authentication.user) AS users FROM datamodel=Authentication BY Authentication.src
âœ… Fast way to list all users who authenticated from each source IP.
ğŸš€ Real Detection Engineering Examples
ğŸ”¸ Suspicious Parent Processes
| tstats values(Processes.process_name) AS child_processes 
  FROM datamodel=Endpoint.Processes 
  WHERE Processes.parent_process_name="powershell.exe" 
  BY Processes.dest
â†’ Shows all unique child processes spawned by PowerShell on each host.
ğŸ”¸ Failed Logons per User
| tstats values(Authentication.src) AS src_ips 
  count FROM datamodel=Authentication 
  WHERE Authentication.action="failure" 
  BY Authentication.user
â†’ Lists all unique source IPs that failed to log in for each user.
âœ… Summary
Feature	values() Function
Purpose	Collects all unique values of a field
Data Type	Multivalue field (array-like)
Works With	stats, eventstats, tstats, streamstats, etc.
Best For	Summaries, correlation searches, and enrichment tables
Caution	Large fields can inflate memory â€” use with filters when possible
Would you like me to show you how to use values() together with mvexpand or eval to make detections more actionable (like pivoting from a multivalue list into individual events for correlation)?
You said:
yes
ChatGPT said:
Perfect ğŸ”¥ â€” this is where you move from simple aggregation to powerful correlation logic in Splunk.
Letâ€™s walk through how to use values() together with mvexpand and eval to turn summaries into detection-ready data.

ğŸ§© 1. What Happens with values()
As we said, values() creates a multivalue field, meaning one field can hold several values:
user=robert
src_ips=192.168.1.10 192.168.1.25 10.0.0.15
This is great for summarization, but what if you want to act on each IP individually (like match against a threat list)?
Thatâ€™s where mvexpand comes in.
âš™ï¸ 2. The mvexpand Command
mvexpand turns each value in a multivalue field into its own event (row).
Example:
index=auth
| stats values(src) AS src_ips BY user
| mvexpand src_ips
âœ… Output:
user	src_ips
robert	192.168.1.10
robert	192.168.1.25
robert	10.0.0.15
Now you can treat each source IP individually â€” for enrichment, lookups, or detection logic.
ğŸ’¡ 3. Add eval for Data Shaping
You can use eval before or after expansion to make detections smarter.
Example â€” Normalize field names:

| eval src_ip=src_ips
| fields user src_ip
Or flag suspicious IPs:
| eval is_suspicious=if(match(src_ip,"10\.0\.0\."),"true","false")
ğŸš€ 4. Real Detection Engineering Scenarios
ğŸ”¸ Example 1: Failed Logins From Multiple IPs
| tstats values(Authentication.src) AS src_ips 
        count FROM datamodel=Authentication 
        WHERE Authentication.action="failure" 
        BY Authentication.user
| mvexpand src_ips
| eval src_ip=src_ips
| lookup threat_intel_ips ip AS src_ip OUTPUT severity
| where isnotnull(severity)
âœ… Whatâ€™s happening:
You collect unique failed login IPs per user
Expand them into rows
Compare each against a threat intel feed
ğŸ”¸ Example 2: Processes Spawned by PowerShell
| tstats values(Processes.process_name) AS child_processes 
  FROM datamodel=Endpoint.Processes 
  WHERE Processes.parent_process_name="powershell.exe" 
  BY Processes.dest
| mvexpand child_processes
| eval process=child_processes
| where match(process, "(cmd\.exe|mshta\.exe|wscript\.exe)")
âœ… Flags hosts where PowerShell spawned suspicious children.
ğŸ”¸ Example 3: Multi-user Correlation (Hunting Style)
| tstats values(Authentication.user) AS users 
  FROM datamodel=Authentication 
  WHERE Authentication.action="success" 
  BY Authentication.src
| mvexpand users
| eval normalized_user=lower(users)
| lookup known_users user AS normalized_user OUTPUT is_admin
| where isnull(is_admin)
âœ… Finds successful logins from IPs that authenticated users not recognized as admins.
ğŸ§  Pro Tips for Detection Engineers
Tip	Why It Matters
Filter before expanding	mvexpand multiplies rows â€” filter early to save memory
Use values() â†’ mvexpand â†’ lookup pattern	Standard correlation flow
Use mvcount(field) before expanding	Helps see how â€œwideâ€ your multivalue fields are
Use `	makemv delim="," fieldname`
ğŸ§¾ Summary
Command	Purpose
values(field)	Collects all unique values of a field into one row
mvexpand field	Splits multivalue field into separate events
eval	Used for renaming, normalizing, or flagging each value after expansion
lookup	Common next step â€” correlate each value to intel or baselines
Would you like me to build you a template detection search that chains all of these together â€” tstats + values() + mvexpand + lookup â€” in a real-world detection use case (e.g., â€œSuspicious Login Sourcesâ€ or â€œPowerShell Child Process Activityâ€)?
You said:
yes
ChatGPT said:
ğŸ”¥ Perfect â€” letâ€™s build you a detection engineerâ€“level Splunk template that combines all the power tools you just asked about:
tstats â†’ values() â†’ mvexpand â†’ eval â†’ lookup

Weâ€™ll do this using two real-world detection use cases so you can reuse the pattern across multiple scenarios.

âš”ï¸ Detection Template 1: Suspicious Login Sources (Authentication Data Model)
Goal: Detect users logging in from multiple or unusual IPs, possibly linked to threat intelligence.
ğŸ§  Search Breakdown
| tstats summariesonly=true count 
        values(Authentication.src) AS src_ips 
  FROM datamodel=Authentication 
  WHERE Authentication.action="success" 
  BY Authentication.user, Authentication.app

| mvexpand src_ips

| eval src_ip = src_ips
| fields Authentication.user Authentication.app src_ip count

| lookup threat_intel_ips ip AS src_ip OUTPUT severity, category

| eval severity=coalesce(severity,"none")
| where severity!="none"

| table Authentication.user Authentication.app src_ip severity category count
| rename Authentication.user AS user Authentication.app AS app
ğŸ’¡ What This Does
tstats summariesonly=true â†’ fast pull from CIM Authentication model
values(Authentication.src) â†’ collect all unique login source IPs per user
mvexpand â†’ split into one row per IP
lookup â†’ compare each IP against a threat intel lookup
where â†’ return only matches (bad IPs)
rename/table â†’ clean up for readability
âœ… Example Output
user	app	src_ip	severity	category	count
jdoe	owa	203.0.113.45	high	C2	15
asmith	vpn	185.44.55.22	medium	TOR Exit	8
âš™ï¸ Detection Template 2: Suspicious PowerShell Child Processes (Endpoint Data Model)
Goal: Detect when PowerShell spawns unusual child processes, like cmd.exe, rundll32.exe, or mshta.exe.
ğŸ§  Search Breakdown
| tstats summariesonly=true count 
        values(Processes.process_name) AS child_procs 
  FROM datamodel=Endpoint.Processes 
  WHERE Processes.parent_process_name="powershell.exe" 
  BY Processes.dest, Processes.user

| mvexpand child_procs
| eval child_process = lower(child_procs)

| where match(child_process, "(cmd\.exe|mshta\.exe|rundll32\.exe|wscript\.exe|regsvr32\.exe)")

| lookup baseline_processes process_name AS child_process OUTPUT known_good

| where isnull(known_good)

| table Processes.dest Processes.user child_process count
| rename Processes.dest AS host Processes.user AS user
ğŸ’¡ What This Does
Uses accelerated Endpoint.Processes data model for speed
Collects unique child processes launched by PowerShell
Expands them into individual rows
Filters for known suspicious binaries
Cross-references a baseline lookup (baseline_processes.csv)
Filters out benign entries
âœ… Example Output
host	user	child_process	count
win10-lab	admin	rundll32.exe	3
srv01	svc_backup	mshta.exe	2
ğŸ§© Reusable Detection Pattern
You can reuse this pattern across most CIM data models:
| tstats summariesonly=true values(<Model.Field>) AS <alias> count 
  FROM datamodel=<Model>.<Dataset>
  WHERE <filter>
  BY <grouping-fields>
| mvexpand <alias>
| eval <normalized_field>=lower(<alias>)
| lookup <lookup_table> <lookup_field> AS <normalized_field> OUTPUT <lookup_output_fields>
| where <filter_condition>
| table <fields_you_want>
ğŸš€ Bonus Tip:
When tuning detections:
Add | eval mv_count=mvcount(src_ips) to see spread (e.g., how many IPs per user)
Use | where mv_count>5 to catch abnormally distributed access patterns
Combine values() + dc() to both list and count unique values
Would you like me to show you how to convert one of these detections into a correlation search (with adaptive response and risk scoring) inside Enterprise Security next? Thatâ€™s the step that turns this logic into an automated detection.



ChatGPT can make mistakes. Check important info.
